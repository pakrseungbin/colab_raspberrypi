{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전이학습(Transfer Learning)을 이용한 데이터 분류 프로젝트!\n",
    "- 사전에 학습된(Pretrained) ResNet50모델 사용!\n",
    "- 나만의 데이터셋(Custom dataset) 적용해보기\n",
    "- 완전 연결 계층(fully connected layer) 수정\n",
    "- 코랩을 이용하여 적용!\n",
    "- 라즈베리파이로 이용해보기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코랩에 데이터를 올려보기!\n",
    "### 구글 드라이브도 올려보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# from google.colab import drive\n",
    "# from google.colab.output import eval_js\n",
    "# from imutils import paths\n",
    "# from IPython.display import display, Javascript\n",
    "# from base64 import b64decode\n",
    "\n",
    "# uploaded = files.upload()\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "epoch = 10\n",
    "num_category = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Load images from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 위치\n",
    "data_dir = \"./data\"\n",
    "\n",
    "data_transforms = { \n",
    "                #더 좋은 학습을 위해 데이터 증강기법 도입!\n",
    "                'train': transforms.Compose([\n",
    "                        transforms.RandomResizedCrop(224), #사이즈변환 224x224\n",
    "                        transforms.RandomHorizontalFlip(), #임의의 횡축 접기\n",
    "                        transforms.ToTensor(), #텐서로 바꾸기\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #정규화\n",
    "                ]),\n",
    "                'val': transforms.Compose([\n",
    "                        transforms.Resize(256),#사이즈변환 256x256\n",
    "                        transforms.CenterCrop(224), #중앙 잘라내기\n",
    "                        transforms.ToTensor(), #텐서로 바꾸기\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ]),\n",
    "}\n",
    "\n",
    "train_set = datasets.ImageFolder(data_dir, transform = data_transforms)\n",
    "val_set = datasets.ImageFolder(data_dir, transform = data_transforms)\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir),\n",
    "                                                data_transforms[x])\n",
    "                                                for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"레이블 개수: \", dataset_sizes)\n",
    "print(\"클래스 이름: \", class_names)\n",
    "class_num = len(class_names)\n",
    "print(\"클래스 개수: \", class_num)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# children() -> immediate children modules \n",
    "# modules() -> iterate all modules\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "for name,module in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Finetuning the convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 마지막 부분을 기존의 1000->2로 바꿔줍니다.\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, class_num)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 통계적 경사하강법실시합니다.\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#Adam도 좋은 학습 Optimizer입니다.\n",
    "# optimizer_ft= optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습률 감소를 매 7에폭마다 0.1씩 감소시켜줍니다.\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수업시간에 배운 위에는 전이학습을(Transfer Learning)을 이용하여 \n",
    "#어느정도 학습 weight를 갱신시키고 싶지 않다면? 다음과 같은 주석을 해제시켜주면 됩니다.\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in model.children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss func & optimizer\n",
    "# model.parameters() also works because of the cell right above\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.layer1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 진행률 코드관련\n",
    "import re\n",
    "from tqdm import trange\n",
    "\n",
    "class DescStr:\n",
    "\tdef __init__(self):\n",
    "\t  self._desc = ''\n",
    "\t\n",
    "\tdef write(self, instr):\n",
    "\t  self._desc += re.sub('\\n|\\x1b.*|\\r', '', instr)\n",
    "\t\n",
    "\tdef read(self):\n",
    "\t  ret = self._desc\n",
    "\t  self._desc = ''\n",
    "\t  return ret\n",
    "\t\n",
    "\tdef flush(self):\n",
    "\t  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    tbar = trange(num_epochs)\n",
    "    desc = DescStr()\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tbar:\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 각 Epoch당 돌아줍니다.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                tbar.set_description(desc.read()) #진행률관련\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 기울기 감소법\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 포워드\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) #가장 높은 확률의 예측값 골라내기\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # 역전파, 최적화 \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # 정확도 관련\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #맞는것들이 있는것들만 추려내기\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            #에폭 손실 체크\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #정확도체크\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]  \n",
    "            tbar.set_postfix(epoch = f'{epoch}/{num_epochs}', \\\n",
    "                            # 표시하고 싶은 변수 입력\n",
    "                            loss = epoch_loss, accuracy = epoch_acc.item()* 100.) \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 최고의 모델을 반환시켜줍니다.\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "#테스트 데이터는 데이터 증강을 하지 않습니다.\n",
    "test_transform = transforms.Compose([\n",
    "                        transforms.Resize((224, 224)), #사이즈변환 255x255 \n",
    "                        transforms.ToTensor(), #텐서로 바꾸기\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #정규화\n",
    "                ])\n",
    "\n",
    "test_set = datasets.ImageFolder(data_dir, transform = test_transform)\n",
    "test_batch = DataLoader(test_set, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종 테스트\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for img,label in test_batch:\n",
    "    img = Variable(img).cuda()\n",
    "    label = Variable(label).cuda()\n",
    "    \n",
    "    output = model(img)\n",
    "    _, pred = torch.max(output.data,1)\n",
    "    \n",
    "    total += label.size(0)\n",
    "    correct += (pred == label.data).sum()   \n",
    "\n",
    "print(\"Accuracy: {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Save\n",
    "### 모델을 저장해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장하기\n",
    "torch.save(model, './model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Load\n",
    "### 모델을 불러와 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈 모델 불러오기\n",
    "model = models.resnet50(pretrained=False)\n",
    "# 가장 마지막 부분을 기존의 1000->2로 바꿔줍니다.\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, class_num)\n",
    "model = model.to(device)\n",
    "#모델안의 값을 출력\n",
    "for idx, i in enumerate(model.parameters()):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그동안 학습한 값을 확인\n",
    "model = (torch.load('./model.pth', map_location=\"cuda:0\"))  # 사용할 GPU 장치 번호를 선택합니다.\n",
    "for idx, i in enumerate(model.parameters()):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사진을 찍어 관찰해보세요!\n",
    "### 사진을 직접 찍고 결과를 관찰해 봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model.forward(image)\n",
    "    \n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    \n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # 확률과 클래스를 반환\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def take_photo(filename=name+'_with_mask.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Take picture with mask';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 경로를 받아오면 딥러닝 형태로 변환해주는 함수\n",
    "def process_image(image_path):\n",
    "    # Load Image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # 사이즈\n",
    "    width, height = img.size\n",
    "    img = img.resize((255, int(255*(height/width))) if width < height else (int(255*(width/height)), 255)) # 255 x 255 사이즈로 변환\n",
    "    \n",
    "    # 변화된 사이즈\n",
    "    width, height = img.size\n",
    "    left = (width - 224)/2\n",
    "    top = (height - 224)/2\n",
    "    right = (width + 224)/2\n",
    "    bottom = (height + 224)/2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    \n",
    "    img = np.array(img)\n",
    "    print(img.shape)\n",
    "    # Chnnel이 먼저되게끔 설정(tensor로 변환)\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    \n",
    "    # 0~1로 변환\n",
    "    img = img/255\n",
    "    \n",
    "    # Normalize 실시\n",
    "    img[0] = (img[0] - 0.485)/0.229\n",
    "    img[1] = (img[1] - 0.456)/0.224\n",
    "    img[2] = (img[2] - 0.406)/0.225\n",
    "    \n",
    "    # 배치사이즈삽입 1\n",
    "    img = img[np.newaxis,:]\n",
    "    \n",
    "    # Turn into a torch tensor\n",
    "    image = torch.from_numpy(img)\n",
    "    image = image.float()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Image\n",
    "image = process_image(\"data/dogs/retriever.jpg\")\n",
    "# Give image to model to predict output\n",
    "\n",
    "top_prob, top_class = predict(image.cuda(), model)\n",
    "print(top_prob, top_class)\n",
    "# Show the image\n",
    "\n",
    "# Print the results\n",
    "print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of \", top_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(\"data/dogs/retriever.jpg\"))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch모델을 라즈베리파이에 넣기위하여 소형화 시키기 위한 작업\n",
    "## Pytorch는 매우크기 때문에 이를 저전력 모델에 넣기 위하여 소형화 시키는 작업을 해야합니다.\n",
    "이를 위하여 Tensorflow-Lite라는 모델로 변환시켜주려고 합니다.\n",
    "Pytorchs는 Facebook에서 만든 Framework이기 때문에 공동 Deep Learning 규약인 ONNX(Open standard for machine learning)를 거쳐\n",
    "Google사의 Tensorflow 형태로 변형시켜준뒤에 Tensorflow-Lite로 변형시켜주고자 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./torch2tflite/setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./torch2tflite/torch2tflite/converter.py\\\n",
    "    --torch-path ./model.pth\\\n",
    "    --tflite-path model.tflite\\\n",
    "    --target-shape 224 224 3\\\n",
    "    --seed 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
